## 特征1、z_score

标准分，一个个体到集合mean的偏离，以标准差为单位，表达个体距mean相对“平均偏离水平（std dev表达）”的偏离程度，常用来比对来自不同集合的数据。

在模型中，z_score用来衡量窗口数据中，中间值的偏离程度。

## 算法流程

1 排除最后一个值；

3 求剩余序列的平均值；

4 全序列减去上面这个平均值；

5 求剩余序列的标准差；

6 （ 中间三个数的平均值-全序列均值）/ 全序列标准差

## 特征2、格拉斯异常值

Grubbs测试是一种从样本中找出outlier的方法，所谓outlier，是指样本中偏离平均值过远的数据，他们有可能是极端情况下的正常数据，也有可能是测量过程中的错误数据。使用Grubbs测试需要总体是正态分布的。

## 算法流程

样本从小到大排序；

求样本的mean和std.dev.；

计算min/max与mean的差距，更大的那个为可疑值；

求可疑值的z-score (standard score)，如果大于Grubbs临界值，那么就是outlier；

Grubbs临界值可以查表得到，它由两个值决定：检出水平α（越严格越小），样本数量n
排除outlier，对剩余序列循环做 1-5 步骤。

由于这里需要的是异常判定，只需要判断tail_avg是否outlier即可。

## 特征3、stddev_from_average

该算法类似于3sigma准则。 当数据服从高斯分布时，数值分布在（μ-3σ,μ+3σ)区间内的概率为99.74。所以，可以这么认为，当数据分布区间超过这个区间时，即可认为是异常数据。该算法使用`(t-mean)/std` 作为特征，用于衡量中间三个值的平均值相对于3σ的距离。

该算法的特点是可以有效屏蔽 “在一个点上突变到很大的异常值但在下一个点回落到正常水平” 的情况，即屏蔽单点毛刺：因为它使用的是3个点的均值（有效缓和突变），和整个序列比较（均值可能被异常值拉大），导致判断正常。

## 算法流程

1、求窗口数据的平均值。 (mean)

2、求窗口数据的标准差。 (std)

3、求窗口数据中间3个值的平均值。 （t）

4、使用(t-mean)/std作为特征。

## 特征4、stddev_from_ewma

类似于特征3，不过在计算`(t-mean)/std`时，使用的mean，std分别为对窗口数据进行移动加权平均后的平均值以及方差。

## 特征5、histogram_bins

该算法和以上都不同，它首先将timeseries划分成15个宽度相等的直方，然后判断tail_avg所在直方内的元素是否<=20，如果是，则异常。

直方的个数和元素个数判定需要根据自己的metrics调整，不然在数据量小的时候很容易就异常了。

## 特征6、median_absolute_deviation

\```
Median

大部分情况下我们用mean来表达一个集合的平均水平（average），但是在某些情况下存在少数极大或极小的outlier，拉高或拉低了（skew）整体的mean，造成估计的不准确。此时可以用median（中位数）代替mean描述平均水平。Median的求法很简单，集合排序中间位置即是，如果集合总数为偶数，则取中间二者的平均值。

Median of deviation（MAD）

同mean一样，对于median我们也需要类似standard deviation这样的指标来表达数据的紧凑/分散程度，即偏离average的平均距离，这就是MAD。MAD顾名思义，是deviation的median，而此时的deviation = abs( 个体 – median )，避免了少量outlier对结果的影响，更robust。
\```

绝对中位差实际求法是用原数据减去中位数后得到的新数据的绝对值的中位数。

1、原数据-中位值=新数据

2、新数据的绝对值的中位数作为特征。

## 特征7、mean_subtraction_cumulation

该特征类似于3-sigma准则。

不能理解地方： 为何减去最后一个值？

## 算法流程

1、排除全序列（暂称为all）最后一个值（last datapoint），求剩余序列（暂称为rest，0..length-2）的mean；

2、rest序列中每个元素减去rest的mean，再求标准差；

3、求窗口数据中间点到rest mean的距离，即 abs(last datapoint – rest mean)；

## 总特征

总的训练特征为：时间窗口特征 + OneHot特征 + Timestamp所属的星期作为特征，label选取时间窗口中间点的标签。

因为选择了窗口数据的中间位置的点作为label值，所以在窗口移动过程中，在数据起始点和终结点会丢失 datasize -( windowsize / 2 ) 个数据。 （datasize为数据的总量，windowsize为时间窗口的大小).

在最终提交的结果中，确实的数据点的预测结果，用0补充。